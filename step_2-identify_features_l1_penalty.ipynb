{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Identify Salient Features Using $\\ell1$-penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Domain and Data\n",
    "\n",
    "Using Madelon, an artificial dataset, to create feature selection models.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Modify the benchmark model to eliminate some features using regularization.\n",
    "\n",
    "### Solution Statement\n",
    "\n",
    "Modifying the benchmark step by choosing l1 penalty, and lower C values, the regularization effect will eliminate some features by pushing their coefficients to zero.\n",
    "\n",
    "\n",
    "### Metric\n",
    "\n",
    "Mean accuracy of the model is the metric for deciding if the model performing well and selected features are the important ones. Also the coefficient absolute value threshold for considering a feature important is set to 0.001.\n",
    "\n",
    "### Benchmark\n",
    "\n",
    "Based on the data nature and experience between 5 to 10 features would be enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Implement the following code pipeline using the functions you write in `lib/project_5.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/identify_features.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib.project_5 import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proj5_conn = {\n",
    "    \"url\" : \"joshuacook.me\",\n",
    "    \"port\" : \"5432\",\n",
    "    \"database\" : \"dsi\",\n",
    "    \"table\" : \"madelon\",\n",
    "    \"user\" : \"dsi_student\",\n",
    "    \"password\" : \"correct horse battery staple\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database and got the data successfully.\n",
      "Data dictionary created.\n",
      "Data is scaled.\n",
      "Transformer is  not found.\n",
      "No grid search.\n"
     ]
    }
   ],
   "source": [
    "step2_b_output = (pipeline(proj5_conn, StandardScaler(), model=LogisticRegression(C=0.0225, penalty=\"l1\"), \n",
    "                    random_state=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step2_b_output[\"scaler\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0225, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step2_b_output[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.62666666666666671, 0.60999999999999999)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step2_b_output[\"train_score\"], step2_b_output[\"test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame(step2_b_output[\"features\"], columns=[\"Feature\", \"Coefficient\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features[\"abs_coefs\"] = abs(features[\"Coefficient\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>abs_coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>feat_475</td>\n",
       "      <td>0.347557</td>\n",
       "      <td>0.347557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>feat_048</td>\n",
       "      <td>0.063738</td>\n",
       "      <td>0.063738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>feat_424</td>\n",
       "      <td>0.029566</td>\n",
       "      <td>0.029566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>feat_317</td>\n",
       "      <td>0.026449</td>\n",
       "      <td>0.026449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>feat_205</td>\n",
       "      <td>-0.008702</td>\n",
       "      <td>0.008702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature  Coefficient  abs_coefs\n",
       "475  feat_475     0.347557   0.347557\n",
       "48   feat_048     0.063738   0.063738\n",
       "424  feat_424     0.029566   0.029566\n",
       "317  feat_317     0.026449   0.026449\n",
       "205  feat_205    -0.008702   0.008702"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.sort_values(by=\"abs_coefs\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_features = features[features[\"abs_coefs\"] > 0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feat_004</td>\n",
       "      <td>0.002461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>feat_048</td>\n",
       "      <td>0.063738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>feat_088</td>\n",
       "      <td>-0.002180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>feat_205</td>\n",
       "      <td>-0.008702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>feat_317</td>\n",
       "      <td>0.026449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>feat_424</td>\n",
       "      <td>0.029566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>feat_475</td>\n",
       "      <td>0.347557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature  Coefficient\n",
       "4    feat_004     0.002461\n",
       "48   feat_048     0.063738\n",
       "88   feat_088    -0.002180\n",
       "205  feat_205    -0.008702\n",
       "317  feat_317     0.026449\n",
       "424  feat_424     0.029566\n",
       "475  feat_475     0.347557"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_features[[\"Feature\", \"Coefficient\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "num_features_one_hundredth = []\n",
    "num_features_one_thousandth = []\n",
    "for c in range(7):\n",
    "    outputs.append(pipeline(proj5_conn, StandardScaler(), model=LogisticRegression(C=10**(c-3), penalty=\"l1\"), \n",
    "                verbose=False, random_state=10))\n",
    "    features = pd.DataFrame(outputs[c][\"features\"], columns=[\"Feature\", \"Coefficient\"])\n",
    "    features[\"abs_coefs\"] = abs(features[\"Coefficient\"])\n",
    "    num_features_one_hundredth.append(features[features[\"abs_coefs\"] > 0.01].shape[0])\n",
    "    num_features_one_thousandth.append(features[features[\"abs_coefs\"] > 0.001].shape[0])\n",
    "scores = pd.DataFrame([(x[\"train_score\"], x[\"test_score\"]) for x in outputs], columns=[\"train_score\", \"test_score\"])\n",
    "c_vals = [10**(c-3) for c in range(7)]\n",
    "scores[\"C_value\"] = c_vals\n",
    "scores[\"num_features_one_hundredth\"] = num_features_one_hundredth\n",
    "scores[\"num_features_one_thousandth\"] = num_features_one_thousandth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>C_value</th>\n",
       "      <th>num_features_one_hundredth</th>\n",
       "      <th>num_features_one_thousandth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.498667</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.738667</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.100</td>\n",
       "      <td>215</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.779333</td>\n",
       "      <td>0.562</td>\n",
       "      <td>1.000</td>\n",
       "      <td>424</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.780667</td>\n",
       "      <td>0.566</td>\n",
       "      <td>10.000</td>\n",
       "      <td>460</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.570</td>\n",
       "      <td>100.000</td>\n",
       "      <td>463</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.570</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>463</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_score  test_score   C_value  num_features_one_hundredth  \\\n",
       "0     0.498667       0.504     0.001                           0   \n",
       "1     0.616667       0.610     0.010                           1   \n",
       "2     0.738667       0.576     0.100                         215   \n",
       "3     0.779333       0.562     1.000                         424   \n",
       "4     0.780667       0.566    10.000                         460   \n",
       "5     0.783333       0.570   100.000                         463   \n",
       "6     0.783333       0.570  1000.000                         463   \n",
       "\n",
       "   num_features_one_thousandth  \n",
       "0                            0  \n",
       "1                            1  \n",
       "2                          267  \n",
       "3                          465  \n",
       "4                          495  \n",
       "5                          498  \n",
       "6                          497  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "num_features_one_hundredth = []\n",
    "num_features_one_thousandth = []\n",
    "for c in range(40):\n",
    "    outputs.append(pipeline(proj5_conn, StandardScaler(), model=LogisticRegression(C=c*0.0005+0.01, penalty=\"l1\"), \n",
    "                   verbose=False, random_state=10))\n",
    "    features = pd.DataFrame(outputs[c][\"features\"], columns=[\"Feature\", \"Coefficient\"])\n",
    "    features[\"abs_coefs\"] = abs(features[\"Coefficient\"])\n",
    "    num_features_one_hundredth.append(features[features[\"abs_coefs\"] > 0.01].shape[0])\n",
    "    num_features_one_thousandth.append(features[features[\"abs_coefs\"] > 0.001].shape[0])\n",
    "scores = pd.DataFrame([(x[\"train_score\"], x[\"test_score\"]) for x in outputs], columns=[\"train_score\", \"test_score\"])\n",
    "c_vals = [c*0.0005+0.01 for c in range(40)]\n",
    "scores[\"C_value\"] = c_vals\n",
    "scores[\"num_features_one_hundredth\"] = num_features_one_hundredth\n",
    "scores[\"num_features_one_thousandth\"] = num_features_one_thousandth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>C_value</th>\n",
       "      <th>num_features_one_hundredth</th>\n",
       "      <th>num_features_one_thousandth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.621333</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.621333</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.623333</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.624667</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.625333</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.625333</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.624667</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.627333</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.628667</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.628000</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.628667</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.629333</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.630667</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.635333</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.636667</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.641333</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.649333</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>23</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.650667</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_score  test_score  C_value  num_features_one_hundredth  \\\n",
       "0      0.616667       0.610   0.0100                           1   \n",
       "1      0.616667       0.610   0.0105                           1   \n",
       "2      0.616667       0.610   0.0110                           1   \n",
       "3      0.616667       0.610   0.0115                           1   \n",
       "4      0.616667       0.610   0.0120                           1   \n",
       "5      0.616667       0.610   0.0125                           1   \n",
       "6      0.616667       0.610   0.0130                           1   \n",
       "7      0.616667       0.610   0.0135                           1   \n",
       "8      0.616667       0.610   0.0140                           1   \n",
       "9      0.616667       0.610   0.0145                           1   \n",
       "10     0.616667       0.608   0.0150                           1   \n",
       "11     0.616667       0.610   0.0155                           2   \n",
       "12     0.621333       0.612   0.0160                           2   \n",
       "13     0.621333       0.612   0.0165                           2   \n",
       "14     0.623333       0.608   0.0170                           2   \n",
       "15     0.624667       0.608   0.0175                           2   \n",
       "16     0.625333       0.608   0.0180                           2   \n",
       "17     0.625333       0.608   0.0185                           2   \n",
       "18     0.624667       0.606   0.0190                           2   \n",
       "19     0.626667       0.608   0.0195                           3   \n",
       "20     0.626667       0.610   0.0200                           4   \n",
       "21     0.627333       0.610   0.0205                           4   \n",
       "22     0.626000       0.608   0.0210                           4   \n",
       "23     0.626667       0.608   0.0215                           4   \n",
       "24     0.628667       0.610   0.0220                           4   \n",
       "25     0.626667       0.610   0.0225                           4   \n",
       "26     0.628000       0.608   0.0230                           5   \n",
       "27     0.628667       0.602   0.0235                           5   \n",
       "28     0.630000       0.602   0.0240                           6   \n",
       "29     0.629333       0.600   0.0245                           7   \n",
       "30     0.630000       0.598   0.0250                           8   \n",
       "31     0.630667       0.602   0.0255                          11   \n",
       "32     0.635333       0.598   0.0260                          15   \n",
       "33     0.636667       0.598   0.0265                          19   \n",
       "34     0.641333       0.596   0.0270                          20   \n",
       "35     0.646667       0.592   0.0275                          22   \n",
       "36     0.649333       0.592   0.0280                          23   \n",
       "37     0.650000       0.594   0.0285                          23   \n",
       "38     0.652000       0.596   0.0290                          24   \n",
       "39     0.650667       0.596   0.0295                          26   \n",
       "\n",
       "    num_features_one_thousandth  \n",
       "0                             1  \n",
       "1                             1  \n",
       "2                             1  \n",
       "3                             1  \n",
       "4                             1  \n",
       "5                             1  \n",
       "6                             1  \n",
       "7                             1  \n",
       "8                             1  \n",
       "9                             1  \n",
       "10                            2  \n",
       "11                            2  \n",
       "12                            2  \n",
       "13                            2  \n",
       "14                            2  \n",
       "15                            2  \n",
       "16                            2  \n",
       "17                            3  \n",
       "18                            4  \n",
       "19                            4  \n",
       "20                            4  \n",
       "21                            4  \n",
       "22                            4  \n",
       "23                            5  \n",
       "24                            5  \n",
       "25                            7  \n",
       "26                            8  \n",
       "27                           11  \n",
       "28                           17  \n",
       "29                           19  \n",
       "30                           20  \n",
       "31                           22  \n",
       "32                           23  \n",
       "33                           24  \n",
       "34                           28  \n",
       "35                           30  \n",
       "36                           31  \n",
       "37                           34  \n",
       "38                           35  \n",
       "39                           37  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
